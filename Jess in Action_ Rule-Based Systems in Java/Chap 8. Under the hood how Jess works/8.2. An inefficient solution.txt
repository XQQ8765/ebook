8.2. An inefficient solution

The obvious implementation of pattern matching would be to keep a list of the rules and simply check each one¡¯s left-hand side (LHS) in turn against the working memory, forming a set of activation records for any that match. After choosing one rule and executing it, you could discard the set of activation records and start again. You might call this the rules finding facts approach. It is obviously not very efficient and doesn¡¯t scale well. After every rule firing, the system must recheck every fact against every rule. Doubling the number of facts or the number of rules roughly halves the performance of the system.

It is difficult to analyze pattern-matching algorithms like this one in the general case, because the actual performance is dependent on the makeup of working memory and on the exact nature of the rules. For the example rule in the previous section, though, we can say that this naive algorithm will take time proportional to the product B1B2 on each cycle, where B1 is the number of books and B2 is the number of borrowers. This is easy to see; on each cycle, every book must be checked to see if it is overdue, and the overdue ones must be checked against every borrower to find the right address. On the average, for many rules, the worst-case performance of this simple algorithm will be something like the B1B2 expression, extended to deal with any number of patterns and multiplied by the number of rules. We could write the result RFP, where R is the number of rules, F is the total number of facts, and P is the average number of patterns per rule. If P is 2, then the runtime will scale as the square of the number of facts; doubling the number of facts will multiply the runtime by a factor of 4.

